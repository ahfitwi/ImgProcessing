{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiled by :\n",
    "      Alem H Fitwi, \n",
    "      PhD Student, ECE (Privacy, ML/DNN, & Chaotic Encryption)\n",
    "      GA-Data Analystics Specialist,\n",
    "      Binghamton University-State University of New York\n",
    "      Since August, 2017 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./figs/dori.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing USing Python\n",
    "1. What is Image Processing?\n",
    "2. Python for Image Processing\n",
    "3. Image Processing Concepts\n",
    "4. Digital Recognition Board"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is Image Processing?\n",
    "- **Image processing** is a method to perform some operations on an image, in order to get an enhanced image or to extract some useful information from it. \n",
    "- It is a type of signal processing in which input is an image and output may be image or characteristics/features associated with that image.\n",
    "- The method of performing operationson an image to achieve a certain goals (enhancement or extraction of features)\n",
    "- A singnal processing where the input is an image /video-frame but the output is either enhanced image or characters or features or tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"./figs/ip.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Applications**:\n",
    "    - Pose Tracking\n",
    "    - Surveillance (physical security and public safety)\n",
    "    - Autodriving cars/Driverless cars (Tesla, Audi, ...)\n",
    "    - Medical Images (X-ray, CT Scan, MRI, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Python for Image Processing\n",
    "- Popular frameworks for processing an image are\n",
    "    - SimpleCV\n",
    "    - OpenCV\n",
    "    - SciPy\n",
    "    - Keras\n",
    "    - NumPy\n",
    "    - TensorFlow\n",
    "    - PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Image Processing Concepts\n",
    "- **A. Image Filtering**: the process of modifying an image by changing its shade or color of the pixels used to increase brightness and contrast.\n",
    "    - In time domain, or\n",
    "    - In Frequency domain\n",
    "    \n",
    "    <img src = './figs/filter.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **B. Layer Padding**: a term relevant to convolutional neural networks as it refers to the amount of pixels added in an image when it is being processed by the kernel or filter.\n",
    "\n",
    "<img src = './figs/pd.png'>\n",
    "\n",
    "- **C. Thresholding**: converts everything to white  or black based on threshold value in the process of image segmentation. \n",
    "\n",
    "<img src = './figs/thre.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **D. Connected Components**: labeling scans an image and groups its pixels into components based on pixel connectivity, i.e. all pixels in a connected component share similar pixel intensity values and are in some way connected with each other.\n",
    "<img src = './figs/cc.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Digital Recognition Board\n",
    "\n",
    "### 4.1 Using keras framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  A. Install and import Keras framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Load Images and preprocess image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mnist.load_data()\n",
    "(X_train, y_train), (X_test, y_test) = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[0])\n",
    "plt.title(y_train[0])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[408])\n",
    "plt.title(y_train[408])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[408], cmap = 'gray')\n",
    "plt.title(y_train[408])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((-1, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Create Model\n",
    "- Using a keras framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Conv2D, AveragePooling2D, Flatten\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convolutional Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters = 4, kernel_size =(5,5),\n",
    "         activation = 'relu', input_shape = (28,28, 1)))\n",
    "\n",
    "model.add(AveragePooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters = 4, kernel_size =(7,7),\n",
    "         activation = 'relu'))\n",
    "model.add(AveragePooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Flaatening the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(units = 10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"sparse_categorical_crossentropy\",\n",
    "              optimizer = 'adam', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs =1, batch_size =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svn = cv2.imread(\"./figs/svn.png\", cv2.IMREAD_GRAYSCALE)\n",
    "svn = cv2.resize(svn, (28,28))\n",
    "plt.imshow(svn)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(svn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svn1 =svn.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_classes(svn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_test[7006])\n",
    "plt.title(y_train[7006])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "three = X_test[7006].reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_classes(three)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Save the model\n",
    "    - In hierarchical Data Format(HDF) --> h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"./models/digitsClassifier.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Loading a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame, sys\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from pygame.locals import *\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(img_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.resize(np.uint8(img_arr), (28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WHITE =(255,255,255)\n",
    "MODEL = load_model(\"./models/digitsClassifier.h5\")\n",
    "BLACK = (0,0,0)\n",
    "pygame.init()\n",
    "BOUNDARYINC = 5\n",
    "WINDOWSIZEX = 640\n",
    "WINDOWSIZEY = 480\n",
    "IMAGESAVE = False\n",
    "PREDICT = True\n",
    "DISPLAY_SURFACE = pygame.display.set_mode((640, 480))\n",
    "WHITE_INT = DISPLAY_SURFACE.map_rgb(WHITE)\n",
    "pygame.display.set_caption(\"Alem Demo\")\n",
    "\n",
    "iswriting = False\n",
    "\n",
    "number_xcord = []\n",
    "number_ycord = []\n",
    "\n",
    "img_cnt = 1\n",
    "\n",
    "while True:\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == QUIT:\n",
    "            pygame.quit()\n",
    "            sys.exit()\n",
    "        if event.type == MOUSEMOTION and iswriting:\n",
    "            xcord, ycord = event.pos\n",
    "            pygame.draw.circle(DISPLAY_SURFACE, WHITE, \n",
    "                               (xcord, ycord), 4, 0)\n",
    "            \n",
    "            number_xcord.append(xcord)\n",
    "            number_ycord.append(ycord)\n",
    "        if event.type == MOUSEBUTTONDOWN:\n",
    "            iswriting = True\n",
    "        \n",
    "        if event.type == MOUSEBUTTONUP:\n",
    "            iswriting = False\n",
    "            number_xcord = sorted(number_xcord)\n",
    "            number_ycord = sorted(number_ycord)\n",
    "            \n",
    "            rect_min_x, rect_max_x = max(\n",
    "            number_xcord[0]-BOUNDARYINC, 0), min(WINDOWSIZEX,\n",
    "            number_xcord[-1]+BOUNDARYINC)\n",
    "            \n",
    "            rect_min_y, rect_max_y = max(\n",
    "            number_ycord[0]-BOUNDARYINC, 0), min(WINDOWSIZEY,\n",
    "            number_ycord[-1]+BOUNDARYINC)\n",
    "            \n",
    "            number_xcord = []\n",
    "            number_ycord = []\n",
    "            img_arr = np.array(pygame.PixelArray(DISPLAY_SURFACE))\n",
    "            #print(img_arr.shape)\n",
    "            if IMAGESAVE:\n",
    "                cv2.imrite(\"image.png\")\n",
    "            if PREDICT:\n",
    "                image = cv2.resize(np.uint8(img_arr), (28,28))\n",
    "                image = np.pad(image, (10,10), 'constant',constant_values = 0)\n",
    "                image = cv2.resize(image, (28,28))/WHITE_INT\n",
    "                labe = str([np.argmax(MODEL.predict(\n",
    "                    image.reshape(-1,28,28,1)))]).title()\n",
    "                RED =(255,0,0)\n",
    "                pygame.draw.rect(DISPLAY_SURFACE, RED, \n",
    "                    (rect_min_x, rect_min_y, \n",
    "                     rect_max_x-rect_min_y,\n",
    "                     rect_max_y-rect_min_y), 3)\n",
    "            if event.type == KEYDOWN:\n",
    "                if event.unicode == 'N':\n",
    "                    DISPLAY_SURFACE.fill(BLACK)\n",
    "                    \n",
    "        pygame.display.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Using OpenCV\n",
    "- Learn Computer Vision with OpenCV Library using Python\n",
    "- Computer vision is an interdisciplinary scientific field that deals with how computers can gain high-level understanding from digital images or videos. From the perspective of engineering, it seeks to understand and automate tasks that the human visual system can do\n",
    "- Colors: (BGR)\n",
    "    - RED: (0,0,255)\n",
    "    - GREEN: (0,255,0)\n",
    "    - BLUE: (255,0,0)\n",
    "- Other colors:\n",
    "    - BLACK = (0, 0, 0)\n",
    "    - WHITE = (255, 255, 255)\n",
    "- Mixing color components results in more colors:  \n",
    "    - CYAN = (255, 255, 0)\n",
    "    - MAGENTA = (255, 0, 255)\n",
    "    - YELLOW = (0, 255, 255)\n",
    "\n",
    "#### 1. Image Fundamentals\n",
    "- Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image reading as colored\n",
    "import numpy as np\n",
    "import cv2\n",
    "img=cv2.imread('./figs/lenna.png') # Display as it is\n",
    "cv2.imshow('colored', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Reading Image as grayscale\n",
    "    - 0 argument value\n",
    "    - cv2.IMREAD_GRASCALE argument value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image reading as gray with 0 argument\n",
    "import numpy as np\n",
    "import cv2\n",
    "img=cv2.imread('./figs/lenna.png',0) #Display gray image\n",
    "cv2.imshow('dark', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image reading as gray with cv2.IMREAD_GRAYSCALE argument\n",
    "import numpy as np\n",
    "import cv2\n",
    "img=cv2.imread('./figs/lenna.png', cv2.IMREAD_GRAYSCALE) #Display gray image\n",
    "cv2.imshow('dark', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Saving output Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image saving\n",
    "import numpy as np\n",
    "import cv2\n",
    "img=cv2.imread('./figs/lenna.png') \n",
    "img=cv2.imwrite('./figs/lenna.jpg',img) \n",
    "cv2.imshow('original', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Resizing using cv2.resize(image, (W, H))\n",
    "import numpy as np\n",
    "import cv2\n",
    "img=cv2.imread('./figs/lenna.png') \n",
    "img=cv2.resize(img,(20,400)) \n",
    "cv2.imshow('resized', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.Drawing shape and writing text on an image\n",
    "- https://opencv-tutorial.readthedocs.io/en/latest/draw/draw.html\n",
    "- Drawing a Rectangle\n",
    "\n",
    "        cv2.rectangle(image, start_point, end_point, color, thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drawing a Rectangle\n",
    "import numpy as np\n",
    "import cv2\n",
    "pic = np.zeros((500,500,3), dtype='uint8')\n",
    "cv2.rectangle(pic,(0,0),(500,150),(123,200,98), 3, lineType=8, shift=0)\n",
    "cv2.imshow('dark', pic)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Drawing a line\n",
    "\n",
    "        cv.line(image, p0, p1, color, thickness)\n",
    "        cv2.line(image, start_point, end_point, line color, line thickness)\n",
    "- If the image is a gray-scale image, instead of the color triplet, a grayscale value from 0 (black) to 255 (white) is used:        \n",
    "\n",
    "        cv.line(gray_img, p0, p1, 100, 2)\n",
    "        cv.line(gray_img, p1, p2, 255,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drawing a line\n",
    "import numpy as np\n",
    "import cv2\n",
    "pic = np.zeros((500,500,3), dtype='uint8')\n",
    "cv2.line(pic, (350,350),(500,350),(255,0,0), 10)\n",
    "cv2.imshow('dark', pic)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "RED = (0, 0, 255)\n",
    "YELLOW = (0, 255, 255)\n",
    "\n",
    "p0, p1, p2 = (10, 10), (300, 90), (400, 10)\n",
    "\n",
    "img = img = np.zeros((100, 500, 3), np.uint8)\n",
    "cv.line(img, p0, p1, RED, 2)\n",
    "cv.line(img, p1, p2, YELLOW, 5)\n",
    "cv.imshow('RGB', img)\n",
    "\n",
    "gray_img = np.zeros((100, 500), np.uint8)\n",
    "cv.line(gray_img, p0, p1, 100, 2)\n",
    "cv.line(gray_img, p1, p2, 255,5)\n",
    "cv.imshow('Gray', gray_img)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select line thickness with a trackbar\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "RED = (0, 0, 255)\n",
    "p0, p1 = (100, 30), (400, 90)\n",
    "\n",
    "def trackbar(x):\n",
    "    x = max(1, x)\n",
    "    cv.displayOverlay('window', f'thickness={x}')\n",
    "    img[:] = 0 \n",
    "    cv.line(img, p0, p1, RED, x)\n",
    "    cv.imshow('window', img)\n",
    "\n",
    "img = np.zeros((100, 500, 3), np.uint8)\n",
    "cv.line(img, p0, p1, RED, 2)\n",
    "cv.imshow('window', img)\n",
    "cv.createTrackbar('thickness', 'window', 2, 20, trackbar)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select line color with a trackbar\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "RED = (0, 0, 255)\n",
    "GREEN = (0, 255, 0)\n",
    "BLUE = (255, 0, 0)\n",
    "CYAN = (255, 255, 0)\n",
    "MAGENTA = (255, 0, 255)\n",
    "YELLOW = (0, 255, 255)\n",
    "WHITE = (255, 255, 255)\n",
    "\n",
    "colors = (RED, GREEN, BLUE, CYAN, MAGENTA, YELLOW, WHITE)\n",
    "p0, p1 = (100, 30), (400, 90)\n",
    "\n",
    "def trackbar(x):\n",
    "    color = colors[x]\n",
    "    cv.displayOverlay('window', f'color={color}')\n",
    "    img[:] = 0 \n",
    "    cv.line(img, p0, p1, color, 10)\n",
    "    cv.imshow('window', img)\n",
    "\n",
    "img = np.zeros((100, 500, 3), np.uint8)\n",
    "cv.line(img, p0, p1, RED, 10)\n",
    "cv.imshow('window', img)\n",
    "cv.createTrackbar('color', 'window', 0, 6, trackbar)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Drawing a circle\n",
    "    - Syntax: \n",
    "\n",
    "            cv2.circle(image, center_coordinates, radius, color, thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drawing a circle\n",
    "import numpy as np\n",
    "import cv2\n",
    "pic = np.zeros((500,500,3), dtype='uint8')\n",
    "color=(255,0,255)\n",
    "cv2.circle(pic, (250,250),50,color, 30)\n",
    "cv2.imshow('dark', pic)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Writing text\n",
    "    - Syntax: \n",
    "    \n",
    "            cv2.putText(image, text, org, font, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing text\n",
    "import numpy as np\n",
    "import cv2\n",
    "pic = np.zeros((500,500,3), dtype='uint8')\n",
    "font=cv2.FONT_HERSHEY_DUPLEX\n",
    "cv2.putText(pic, 'SUNY', (100,100), font, 3, (255,255,255), 4, cv2.LINE_8)\n",
    "cv2.imshow('dark', pic)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Drawing combination: Line, Rectangle, circle, and Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drawing combination: Line, Rectangle, circle, and Text\n",
    "import numpy as np\n",
    "import cv2\n",
    "pic = np.zeros((500,500,3), dtype='uint8')\n",
    "cv2.rectangle(pic, (0,0),(500,150),(123,200,98), 3, lineType=8, shift=0)\n",
    "font=cv2.FONT_HERSHEY_DUPLEX\n",
    "cv2.putText(pic, 'Udemy', (100,100), font, 3, (255,255,255), 4, cv2.LINE_8)\n",
    "cv2.circle(pic, (250,250),50,(255,0,255))\n",
    "cv2.line(pic, (133,138),(388,133),(0,0,255))\n",
    "cv2.imshow('dark', pic)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.Image Processing\n",
    "- Affine Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Transformations\n",
    "import numpy as np\n",
    "import cv2\n",
    "pic=cv2.imread('./figs/lenna.png')\n",
    "cv2.imshow('orig',pic)\n",
    "cols=pic.shape[1]\n",
    "rows=pic.shape[0]\n",
    "\n",
    "M=np.float32([[1,0,150],[0,1,170]])\n",
    "#M=np.float32([[1,0,-150],[0,1,-170]])\n",
    "shifted=cv2.warpAffine(pic,M,(cols,rows))\n",
    "cv2.imshow('shifted',shifted)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Image Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Rotation\n",
    "import numpy as np\n",
    "import cv2\n",
    "pic=cv2.imread('./figs/lenna.png')\n",
    "cols=pic.shape[1]\n",
    "rows=pic.shape[0]\n",
    "center=(cols/2,rows/2)\n",
    "angle=90\n",
    "#CW: angle=-90 or -1\n",
    "# CCW: angle = 90, or 1\n",
    "M=cv2.getRotationMatrix2D(center,angle,-1)\n",
    "rotate=cv2.warpAffine(pic,M,(cols,rows))\n",
    "cv2.imshow('rotated',rotate)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Image Thresholding\n",
    "    - Simple Thresholding: Here, the matter is straight-forward. For every pixel, the same threshold value is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Thresholding\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "img = cv.imread('./figs/lenna.png',0)\n",
    "ret,thresh1 = cv.threshold(img,127,255,cv.THRESH_BINARY)\n",
    "ret,thresh2 = cv.threshold(img,127,255,cv.THRESH_BINARY_INV)\n",
    "ret,thresh3 = cv.threshold(img,127,255,cv.THRESH_TRUNC)\n",
    "ret,thresh4 = cv.threshold(img,127,255,cv.THRESH_TOZERO)\n",
    "ret,thresh5 = cv.threshold(img,127,255,cv.THRESH_TOZERO_INV)\n",
    "titles = ['Original Image','BINARY','BINARY_INV','TRUNC','TOZERO','TOZERO_INV']\n",
    "images = [img, thresh1, thresh2, thresh3, thresh4, thresh5]\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1),plt.imshow(images[i],'gray',vmin=0,vmax=255)\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The adaptiveMethod decides how the threshold value is calculated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "img = cv.imread('./figs/lenna.png',0)\n",
    "img = cv.medianBlur(img,5)\n",
    "ret,th1 = cv.threshold(img,127,255,cv.THRESH_BINARY)\n",
    "th2 = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_MEAN_C,\\\n",
    "            cv.THRESH_BINARY,11,2)\n",
    "th3 = cv.adaptiveThreshold(img,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C,\\\n",
    "            cv.THRESH_BINARY,11,2)\n",
    "titles = ['Original Image', 'Global Thresholding (v = 127)',\n",
    "            'Adaptive Mean Thresholding', 'Adaptive Gaussian Thresholding']\n",
    "images = [img, th1, th2, th3]\n",
    "for i in range(4):\n",
    "    plt.subplot(2,2,i+1),plt.imshow(images[i],'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Otsu's Binarization\n",
    "    - In global thresholding, we used an arbitrary chosen value as a threshold. In contrast, Otsu's method avoids having to choose a value and determines it automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "img = cv.imread('./figs/lenna.png',0)\n",
    "# global thresholding\n",
    "ret1,th1 = cv.threshold(img,127,255,cv.THRESH_BINARY)\n",
    "# Otsu's thresholding\n",
    "ret2,th2 = cv.threshold(img,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "# Otsu's thresholding after Gaussian filtering\n",
    "blur = cv.GaussianBlur(img,(5,5),0)\n",
    "ret3,th3 = cv.threshold(blur,0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "# plot all the images and their histograms\n",
    "images = [img, 0, th1,\n",
    "          img, 0, th2,\n",
    "          blur, 0, th3]\n",
    "titles = ['Original Noisy Image','Histogram','Global Thresholding (v=127)',\n",
    "          'Original Noisy Image','Histogram',\"Otsu's Thresholding\",\n",
    "          'Gaussian filtered Image','Histogram',\"Otsu's Thresholding\"]\n",
    "for i in range(3):\n",
    "    plt.subplot(3,3,i*3+1),plt.imshow(images[i*3],'gray')\n",
    "    plt.title(titles[i*3]), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(3,3,i*3+2),plt.hist(images[i*3].ravel(),256)\n",
    "    plt.title(titles[i*3+1]), plt.xticks([]), plt.yticks([])\n",
    "    plt.subplot(3,3,i*3+3),plt.imshow(images[i*3+2],'gray')\n",
    "    plt.title(titles[i*3+2]), plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.Image Filtering\n",
    "- Gaussian Blur: \n",
    "    - Image Smoothing using OpenCV Gaussian Blur: As in any other signals, images also can contain different types of noise, especially because of the source (camera sensor). Image Smoothing techniques help in reducing the noise. In OpenCV, image smoothing (also called blurring) could be done in many ways. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guassion Blur\n",
    "import numpy as np\n",
    "import cv2\n",
    "pic=cv2.imread('./figs/lenna.png')\n",
    "matrix=(7,7)\n",
    "blur=cv2.GaussianBlur(pic,matrix,0)\n",
    "cv2.imshow('blurred',blur)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Median Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Median Blur\n",
    "import numpy as np\n",
    "import cv2\n",
    "pic=cv2.imread('./figs/lenna.png')\n",
    "kernel=3\n",
    "median=cv2.medianBlur(pic,kernel)\n",
    "cv2.imshow('median',pic)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Bilateral Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bilateral Filtering\n",
    "import numpy as np\n",
    "import cv2\n",
    "pic=cv2.imread('./figs/lenna.png')\n",
    "cv2.imshow('original',pic)\n",
    "dimpixel=7\n",
    "color=100\n",
    "space=100\n",
    "filter=cv2.bilateralFilter(pic,dimpixel,color,space)\n",
    "cv2.imshow('filter',filter)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Feature Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Canny Edge Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canny Edge Detector\n",
    "import cv2\n",
    "import numpy as np\n",
    "pic = cv2.imread('./figs/lenna.png')\n",
    "\n",
    "thresholdval1=50\n",
    "thresholdval2=100\n",
    "\n",
    "canny=cv2.Canny(pic,thresholdval1,thresholdval2)\n",
    "cv2.imshow('canny',pic)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Video Analysis\n",
    "- Load Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Video\n",
    "import cv2\n",
    "import numpy as np\n",
    "cap=cv2.VideoCapture('./figs/pedestrians.mp4')\n",
    "while cap.isOpened():\n",
    "    ret,frame = cap.read()\n",
    "    if ret:        \n",
    "        cv2.imshow('vid', frame)\n",
    "    else:\n",
    "        break\n",
    "    if cv2.cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Video from camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# define a video capture object\n",
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    ret, frame = vid.read()\n",
    "    cv2.imshow('frame', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "# After the loop release the vid object\n",
    "vid.release()\n",
    "# Destroy all the windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Video\n",
    "import cv2\n",
    "import numpy as np\n",
    "vid = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret,frame = vid.read()\n",
    "    if ret:        \n",
    "        cv2.imshow('vid', frame)\n",
    "    else:\n",
    "        break\n",
    "    if cv2.cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Save video in a different format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "cap=cv2.VideoCapture('./figs/pedestrians.mp4')\n",
    "# fourcc = cv.VideoWriter_fourcc('m', 'p', '4', 'v')\n",
    "fourcc=cv2.VideoWriter_fourcc(*'XVID')\n",
    "fps=30\n",
    "framesize=(640,480)\n",
    "out=cv2.VideoWriter('./figs/sample.avi',fourcc,fps,framesize)\n",
    "while cap.isOpened():\n",
    "    ret,frame = cap.read()\n",
    "    if ret:        \n",
    "        cv2.imshow('vid', frame)\n",
    "    else:\n",
    "        break\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "         break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.Applications\n",
    "- Introduction to image face detection\n",
    "    - Face detection by using Haar feature based cascade classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real time face detection using webcam\n",
    "import cv2\n",
    "import numpy as np\n",
    "#https://github.com/Itseez/opencv/tree/master/data/haarcascades\n",
    "face_cascade=cv2.CascadeClassifier('./model/haarcascade_frontalface_alt.xml')\n",
    "videocapture=cv2.VideoCapture(0)\n",
    "scale_factor=1.3\n",
    "while 1:\n",
    "    ret, pic=videocapture.read()\n",
    "    faces=face_cascade.detectMultiScale(pic, scale_factor, 5)\n",
    "    for(x,y,w,h) in faces:\n",
    "        cv2.rectangle(pic,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "        cv2.putText(pic,'Me', (x,y),font, 2, (255,255,255), 2, cv2.LINE_AA)\n",
    "    print(\"Number_of_faces_found {}\".format(len(faces)))\n",
    "    cv2.imshow('face',pic)    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "         break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
